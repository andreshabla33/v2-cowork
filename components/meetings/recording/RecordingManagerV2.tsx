/**
 * RecordingManagerV2 - Componente de grabaci√≥n con an√°lisis conductual avanzado
 * 
 * Caracter√≠sticas:
 * - Selector de tipo: RRHH, Deals, Equipo
 * - Disclaimer condicional (solo RRHH)
 * - An√°lisis facial avanzado con microexpresiones
 * - An√°lisis de lenguaje corporal
 * - Predicciones de comportamiento
 * - Dashboard espec√≠fico por tipo
 */

import React, { useState, useRef, useCallback, useEffect } from 'react';
import { supabase } from '../../../lib/supabase';
import { useTranscription } from './useTranscription';
import { useCombinedAnalysis, AnalisisResumenTiempoReal } from './useCombinedAnalysis';
import { RecordingTypeSelectorV2 } from './RecordingTypeSelectorV2';
import { AnalysisDashboard } from './AnalysisDashboard';
import { 
  TipoGrabacionDetallado,
  CargoLaboral,
  CONFIGURACIONES_GRABACION_DETALLADO,
  ResultadoAnalisis,
  tienePermisoAnalisis,
} from './types/analysis';

interface RecordingManagerV2Props {
  espacioId: string;
  userId: string;
  userName: string;
  reunionTitulo?: string;
  stream: MediaStream | null;
  cargoUsuario?: CargoLaboral; // Nuevo: cargo del usuario para permisos
  onRecordingStateChange?: (isRecording: boolean) => void;
  onProcessingComplete?: (resultado: ResultadoAnalisis | null) => void;
}

interface ProcessingState {
  step: 'idle' | 'selecting_type' | 'recording' | 'stopping' | 'processing' | 'complete' | 'error';
  progress: number;
  message: string;
  duration: number;
}

export const RecordingManagerV2: React.FC<RecordingManagerV2Props> = ({
  espacioId,
  userId,
  userName,
  reunionTitulo,
  stream,
  cargoUsuario = 'colaborador',
  onRecordingStateChange,
  onProcessingComplete,
}) => {
  // Estados principales
  const [processingState, setProcessingState] = useState<ProcessingState>({
    step: 'idle',
    progress: 0,
    message: '',
    duration: 0,
  });
  const [tipoGrabacion, setTipoGrabacion] = useState<TipoGrabacionDetallado | null>(null);
  const [conAnalisis, setConAnalisis] = useState<boolean>(true);
  const [showTypeSelector, setShowTypeSelector] = useState(false);
  const [showDashboard, setShowDashboard] = useState(false);
  const [resultado, setResultado] = useState<ResultadoAnalisis | null>(null);
  const [resumenTiempoReal, setResumenTiempoReal] = useState<AnalisisResumenTiempoReal | null>(null);

  // Refs
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const durationIntervalRef = useRef<ReturnType<typeof setInterval> | null>(null);
  const startTimeRef = useRef<number>(0);
  const grabacionIdRef = useRef<string>('');
  const transcriptRef = useRef<string>('');
  const videoElementRef = useRef<HTMLVideoElement | null>(null);

  const isRecording = processingState.step === 'recording';
  const config = tipoGrabacion ? CONFIGURACIONES_GRABACION_DETALLADO[tipoGrabacion] : null;

  // Hook de transcripci√≥n
  const {
    startTranscription,
    stopTranscription,
    transcribeAudioBlob,
    fullTranscript,
    segments,
  } = useTranscription({
    grabacionId: grabacionIdRef.current || 'pending',
    idioma: 'es',
    onFullTranscriptUpdate: (text) => {
      transcriptRef.current = text;
    },
  });

  // Obtener tipo base para el hook de an√°lisis (rrhh_entrevista y rrhh_one_to_one -> rrhh)
  const tipoBase = tipoGrabacion 
    ? CONFIGURACIONES_GRABACION_DETALLADO[tipoGrabacion].tipoBase 
    : 'equipo';

  // Hook de an√°lisis combinado (se inicializa cuando se selecciona tipo)
  const combinedAnalysis = useCombinedAnalysis({
    tipoGrabacion: tipoBase,
    grabacionId: grabacionIdRef.current || 'pending',
    participantes: [{ id: userId, nombre: userName }],
    onAnalisisUpdate: (resumen) => {
      setResumenTiempoReal(resumen);
    },
  });

  // Actualizar estado
  const updateState = useCallback((updates: Partial<ProcessingState>) => {
    setProcessingState(prev => ({ ...prev, ...updates }));
  }, []);

  // Manejar clic en bot√≥n de grabar
  const handleRecordClick = useCallback(() => {
    if (isRecording) {
      stopRecording();
    } else {
      setShowTypeSelector(true);
    }
  }, [isRecording]);

  // Manejar selecci√≥n de tipo
  const handleTypeSelect = useCallback((tipo: TipoGrabacionDetallado, analisis: boolean) => {
    setTipoGrabacion(tipo);
    setConAnalisis(analisis);
    setShowTypeSelector(false);
    startRecording(tipo, analisis);
  }, []);

  // Buscar elemento de video
  const findVideoElement = useCallback((): HTMLVideoElement | null => {
    if (!stream) return null;
    
    const videoElements = document.querySelectorAll('video');
    for (const video of videoElements) {
      if (video.srcObject === stream) {
        return video as HTMLVideoElement;
      }
    }
    return null;
  }, [stream]);

  // Iniciar grabaci√≥n
  const startRecording = useCallback(async (tipo: TipoGrabacionDetallado, analisis: boolean = true) => {
    if (!stream) {
      updateState({ step: 'error', message: 'No hay stream de audio/video disponible' });
      return;
    }

    try {
      // Inicializar refs
      chunksRef.current = [];
      transcriptRef.current = '';
      grabacionIdRef.current = crypto.randomUUID();

      // Buscar video element
      const videoEl = findVideoElement();
      if (videoEl) {
        videoElementRef.current = videoEl;
      }

      // Configurar MediaRecorder
      const mimeType = MediaRecorder.isTypeSupported('video/webm;codecs=vp9,opus')
        ? 'video/webm;codecs=vp9,opus'
        : 'video/webm';

      const recorder = new MediaRecorder(stream, {
        mimeType,
        videoBitsPerSecond: 2500000,
        audioBitsPerSecond: 128000,
      });

      recorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          chunksRef.current.push(e.data);
        }
      };

      recorder.onstop = () => {
        processRecording();
      };

      mediaRecorderRef.current = recorder;
      startTimeRef.current = Date.now();

      // Registrar en Supabase
      await supabase.from('grabaciones').insert({
        id: grabacionIdRef.current,
        espacio_id: espacioId,
        creado_por: userId,
        estado: 'grabando',
        inicio_grabacion: new Date().toISOString(),
        tipo: tipo, // Guardar tipo detallado (rrhh_entrevista, deals, equipo, etc.)
        tiene_video: true,
        tiene_audio: true,
        formato: 'webm',
      });

      // Iniciar grabaci√≥n
      recorder.start(1000);

      // Timer de duraci√≥n
      durationIntervalRef.current = setInterval(() => {
        const elapsed = Math.floor((Date.now() - startTimeRef.current) / 1000);
        updateState({ duration: elapsed });
      }, 1000);

      updateState({ 
        step: 'recording', 
        progress: 0, 
        message: `Grabando ${CONFIGURACIONES_GRABACION_DETALLADO[tipo].titulo}...`, 
        duration: 0 
      });
      onRecordingStateChange?.(true);

      // Iniciar transcripci√≥n
      const audioTracks = stream.getAudioTracks();
      if (audioTracks.length > 0) {
        const audioStream = new MediaStream(audioTracks);
        startTranscription(audioStream).catch(err => {
          console.warn('‚ö†Ô∏è Transcripci√≥n en tiempo real no disponible:', err.message);
        });
      }

      // Iniciar an√°lisis combinado (facial + corporal)
      if (videoElementRef.current) {
        await combinedAnalysis.startAnalysis(videoElementRef.current);
      }

      console.log(`üî¥ Grabaci√≥n iniciada: ${tipo.toUpperCase()}`);

    } catch (err: any) {
      console.error('Error iniciando grabaci√≥n:', err);
      updateState({ step: 'error', message: err.message || 'Error al iniciar grabaci√≥n' });
    }
  }, [stream, espacioId, userId, updateState, onRecordingStateChange, startTranscription, findVideoElement, combinedAnalysis]);

  // Detener grabaci√≥n
  const stopRecording = useCallback(async () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      updateState({ step: 'stopping', message: 'Deteniendo grabaci√≥n...' });

      // Limpiar timer
      if (durationIntervalRef.current) {
        clearInterval(durationIntervalRef.current);
        durationIntervalRef.current = null;
      }

      // Detener transcripci√≥n
      await stopTranscription();

      // Detener an√°lisis combinado
      combinedAnalysis.stopAnalysis();

      // Detener MediaRecorder (dispara processRecording via onstop)
      mediaRecorderRef.current.stop();
      onRecordingStateChange?.(false);

      console.log('‚èπÔ∏è Grabaci√≥n detenida');
    }
  }, [updateState, onRecordingStateChange, stopTranscription, combinedAnalysis]);

  // Procesar grabaci√≥n
  const processRecording = useCallback(async () => {
    try {
      const blob = new Blob(chunksRef.current, { type: 'video/webm' });
      const duration = processingState.duration;

      updateState({ step: 'processing', progress: 20, message: 'Procesando transcripci√≥n...' });

      // Obtener transcripci√≥n
      let transcript = transcriptRef.current;
      if (!transcript || transcript.trim().length < 20) {
        transcript = await transcribeAudioBlob(blob) || '';
      }
      if (!transcript || transcript.trim().length < 10) {
        transcript = `[Reuni√≥n de ${Math.round(duration / 60)} minutos]`;
      }

      updateState({ progress: 40, message: 'Generando an√°lisis conductual...' });

      // Obtener resultado de an√°lisis combinado
      const resultadoAnalisis = combinedAnalysis.getResultadoCompleto();

      updateState({ progress: 50, message: 'Guardando transcripci√≥n...' });

      // Guardar transcripci√≥n en Supabase
      if (transcript && transcript.trim().length > 0) {
        const transcripcionRecord = {
          grabacion_id: grabacionIdRef.current,
          texto: transcript,
          inicio_segundos: 0,
          fin_segundos: duration,
          speaker_id: userId,
          speaker_nombre: userName,
          confianza: 0.9,
          idioma: 'es',
        };
        
        const { error: transcError } = await supabase
          .from('transcripciones')
          .insert(transcripcionRecord);
        
        if (transcError) {
          console.error('Error guardando transcripci√≥n:', transcError);
        } else {
          console.log('‚úÖ Transcripci√≥n guardada en Supabase');
        }
      }

      updateState({ progress: 70, message: 'Guardando an√°lisis conductual...' });

      // Guardar an√°lisis en Supabase
      const emotionFrames = resultadoAnalisis.frames_faciales;
      if (emotionFrames.length > 0) {
        const emotionRecords = emotionFrames
          .filter((_, i) => i % 5 === 0) // Cada 5 frames para no saturar
          .map((e) => ({
            id: crypto.randomUUID(),
            grabacion_id: grabacionIdRef.current,
            timestamp_segundos: e.timestamp_segundos,
            emocion_dominante: e.emocion_dominante,
            engagement_score: e.engagement_score,
            participante_id: userId,
            participante_nombre: userName,
          }));

        // Insertar en lotes
        for (let i = 0; i < emotionRecords.length; i += 50) {
          const batch = emotionRecords.slice(i, i + 50);
          const { error: analisisError } = await supabase.from('analisis_comportamiento').insert(batch);
          if (analisisError) {
            console.error('Error guardando an√°lisis:', analisisError);
          }
        }
        console.log(`‚úÖ ${emotionRecords.length} registros de an√°lisis guardados`);
      } else {
        console.warn('‚ö†Ô∏è No hay frames de an√°lisis para guardar');
      }

      updateState({ progress: 80, message: 'Generando resumen AI...' });

      // Generar resumen AI
      const avgEngagement = emotionFrames.length > 0
        ? emotionFrames.reduce((sum, f) => sum + f.engagement_score, 0) / emotionFrames.length
        : 0.5;

      const { data: aiData } = await supabase.functions.invoke('generar-resumen-ai', {
        body: {
          grabacion_id: grabacionIdRef.current,
          espacio_id: espacioId,
          creador_id: userId,
          transcripcion: transcript,
          emociones: emotionFrames.slice(-50),
          duracion_segundos: duration,
          participantes: [userName],
          reunion_titulo: reunionTitulo,
          tipo_grabacion: tipoGrabacion,
          metricas_adicionales: {
            engagement_promedio: avgEngagement,
            microexpresiones_detectadas: resultadoAnalisis.microexpresiones.length,
            tipo_analisis: tipoGrabacion,
          },
        },
      });

      // Actualizar grabaci√≥n en Supabase (metadatos sin archivo de video)
      await supabase.from('grabaciones').update({
        estado: 'completado',
        duracion_segundos: duration,
        fin_grabacion: new Date().toISOString(),
        archivo_nombre: reunionTitulo || `Reuni√≥n ${new Date().toLocaleDateString('es-ES')}`,
      }).eq('id', grabacionIdRef.current);

      // Video procesado localmente - no se sube a storage por privacidad
      console.log('üìπ Video procesado localmente (no subido a storage)');

      // Guardar resultado
      setResultado(resultadoAnalisis);
      setShowDashboard(true);
      updateState({ step: 'complete', progress: 100, message: '¬°An√°lisis completado!' });
      onProcessingComplete?.(resultadoAnalisis);

      // Notificaci√≥n
      await supabase.from('notificaciones').insert({
        usuario_id: userId,
        espacio_id: espacioId,
        tipo: 'analisis_listo',
        titulo: `üìä An√°lisis de ${config?.titulo || 'reuni√≥n'} listo`,
        mensaje: reunionTitulo
          ? `El an√°lisis de "${reunionTitulo}" est√° disponible`
          : 'El an√°lisis de tu reuni√≥n est√° disponible',
        entidad_tipo: 'grabacion',
        entidad_id: grabacionIdRef.current,
      });

      console.log('‚úÖ Procesamiento completo');

    } catch (err: any) {
      console.error('Error procesando grabaci√≥n:', err);
      updateState({ step: 'error', message: err.message || 'Error en el procesamiento' });

      // Marcar grabaci√≥n como error
      await supabase.from('grabaciones').update({
        estado: 'error',
        error_mensaje: err.message || 'Error en procesamiento',
      }).eq('id', grabacionIdRef.current);
    }
  }, [
    processingState.duration, 
    updateState, 
    onProcessingComplete, 
    combinedAnalysis, 
    transcribeAudioBlob,
    userId, 
    userName, 
    espacioId, 
    reunionTitulo, 
    tipoGrabacion,
    config,
  ]);

  // Formatear duraci√≥n
  const formatDuration = (seconds: number): string => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${String(mins).padStart(2, '0')}:${String(secs).padStart(2, '0')}`;
  };

  // Cleanup
  useEffect(() => {
    return () => {
      if (durationIntervalRef.current) {
        clearInterval(durationIntervalRef.current);
      }
      if (mediaRecorderRef.current?.state !== 'inactive') {
        mediaRecorderRef.current?.stop();
      }
    };
  }, []);

  return (
    <>
      {/* Selector de tipo con permisos por cargo */}
      <RecordingTypeSelectorV2
        isOpen={showTypeSelector}
        onClose={() => setShowTypeSelector(false)}
        onSelect={handleTypeSelect}
        cargoUsuario={cargoUsuario}
      />

      {/* Dashboard de resultados */}
      {showDashboard && resultado && (
        <AnalysisDashboard
          resultado={resultado}
          onClose={() => {
            setShowDashboard(false);
            setResultado(null);
            setTipoGrabacion(null);
            updateState({ step: 'idle', progress: 0, message: '', duration: 0 });
          }}
          onExport={() => {
            const json = JSON.stringify(resultado, null, 2);
            const blob = new Blob([json], { type: 'application/json' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `analisis_${resultado.tipo_grabacion}_${new Date().toISOString().slice(0, 10)}.json`;
            a.click();
            URL.revokeObjectURL(url);
          }}
        />
      )}

      {/* Modal de procesamiento */}
      {(processingState.step === 'stopping' || processingState.step === 'processing') && (
        <div className="fixed inset-0 bg-black/70 backdrop-blur-sm z-[300] flex items-center justify-center">
          <div className="bg-zinc-900 rounded-2xl p-6 max-w-md w-full mx-4 border border-white/10 shadow-2xl">
            <div className="text-center">
              <div className="w-16 h-16 mx-auto mb-4 relative">
                <div className="absolute inset-0 border-4 border-indigo-500/30 rounded-full"></div>
                <div 
                  className="absolute inset-0 border-4 border-indigo-500 rounded-full border-t-transparent animate-spin"
                  style={{ animationDuration: '1s' }}
                ></div>
                <div className="absolute inset-0 flex items-center justify-center">
                  <span className="text-2xl">üß†</span>
                </div>
              </div>
              
              <h3 className="text-white font-bold text-lg mb-2">Procesando An√°lisis</h3>
              <p className="text-white/70 text-sm mb-4">{processingState.message}</p>
              
              <div className="w-full bg-white/10 rounded-full h-2 mb-2">
                <div 
                  className="bg-indigo-500 h-2 rounded-full transition-all duration-500"
                  style={{ width: `${processingState.progress}%` }}
                ></div>
              </div>
              <p className="text-white/50 text-xs">{processingState.progress}% completado</p>
            </div>
          </div>
        </div>
      )}

      {/* Error toast */}
      {processingState.step === 'error' && (
        <div className="fixed top-24 right-4 z-[301] animate-slide-in">
          <div className="bg-red-600 text-white px-4 py-3 rounded-xl shadow-2xl flex items-center gap-3">
            <span className="text-2xl">‚ö†Ô∏è</span>
            <div>
              <p className="font-bold text-sm">Error en procesamiento</p>
              <p className="text-xs opacity-80">{processingState.message}</p>
            </div>
            <button 
              onClick={() => updateState({ step: 'idle', message: '' })}
              className="ml-2 w-6 h-6 rounded-full bg-white/20 flex items-center justify-center hover:bg-white/30"
            >
              ‚úï
            </button>
          </div>
        </div>
      )}

      {/* Indicadores en tiempo real durante grabaci√≥n */}
      {isRecording && resumenTiempoReal && (
        <div className="fixed bottom-24 left-4 z-[200] space-y-2">
          {/* Badge de tipo */}
          {config && (
            <div className={`px-3 py-1.5 rounded-full bg-gradient-to-r ${config.color} text-white text-sm font-medium flex items-center gap-2 shadow-lg`}>
              <span>{config.icono}</span>
              <span>{config.titulo}</span>
            </div>
          )}

          {/* M√©tricas en tiempo real */}
          <div className="bg-zinc-900/90 backdrop-blur rounded-xl p-3 border border-white/10 shadow-lg space-y-2 min-w-[200px]">
            <div className="flex items-center justify-between">
              <span className="text-white/60 text-xs">Engagement</span>
              <div className="flex items-center gap-2">
                <div className="w-20 h-1.5 bg-white/10 rounded-full overflow-hidden">
                  <div 
                    className={`h-full rounded-full transition-all ${
                      resumenTiempoReal.engagementActual > 0.6 ? 'bg-green-500' :
                      resumenTiempoReal.engagementActual > 0.4 ? 'bg-yellow-500' : 'bg-red-500'
                    }`}
                    style={{ width: `${resumenTiempoReal.engagementActual * 100}%` }}
                  />
                </div>
                <span className="text-white text-xs font-mono">
                  {Math.round(resumenTiempoReal.engagementActual * 100)}%
                </span>
              </div>
            </div>

            <div className="flex items-center justify-between">
              <span className="text-white/60 text-xs">Emoci√≥n</span>
              <span className="text-white text-sm">
                {resumenTiempoReal.emocionActual === 'happy' && 'üòä'}
                {resumenTiempoReal.emocionActual === 'sad' && 'üò¢'}
                {resumenTiempoReal.emocionActual === 'angry' && 'üò†'}
                {resumenTiempoReal.emocionActual === 'surprised' && 'üò≤'}
                {resumenTiempoReal.emocionActual === 'neutral' && 'üòê'}
                {resumenTiempoReal.emocionActual === 'fearful' && 'üò®'}
                {resumenTiempoReal.emocionActual === 'disgusted' && 'ü§¢'}
                {' '}{resumenTiempoReal.emocionActual}
              </span>
            </div>

            <div className="flex items-center justify-between">
              <span className="text-white/60 text-xs">Postura</span>
              <span className="text-white text-xs capitalize">
                {resumenTiempoReal.posturaActual.replace(/_/g, ' ')}
              </span>
            </div>

            <div className="flex items-center justify-between">
              <span className="text-white/60 text-xs">Microexpr.</span>
              <span className="text-indigo-400 text-xs font-mono">
                {resumenTiempoReal.microexpresionesCount}
              </span>
            </div>

            {/* Alertas */}
            {resumenTiempoReal.alertas.length > 0 && (
              <div className="pt-2 border-t border-white/10">
                {resumenTiempoReal.alertas.slice(0, 2).map((alerta, i) => (
                  <p key={i} className="text-amber-400 text-xs">{alerta}</p>
                ))}
              </div>
            )}
          </div>
        </div>
      )}

      {/* Bot√≥n flotante para iniciar grabaci√≥n con an√°lisis */}
      {processingState.step === 'idle' && !isRecording && (
        <div className="fixed bottom-6 right-6 z-[200]">
          <button
            onClick={() => setShowTypeSelector(true)}
            className="group relative flex items-center gap-3 bg-gradient-to-r from-indigo-600 to-purple-600 hover:from-indigo-500 hover:to-purple-500 text-white px-5 py-3 rounded-2xl shadow-2xl transition-all hover:scale-105"
          >
            <span className="w-4 h-4 bg-red-500 rounded-full animate-pulse"></span>
            <span className="font-bold text-sm">Grabar con An√°lisis</span>
            <span className="text-xl">üß†</span>
            
            {/* Tooltip */}
            <div className="absolute bottom-full mb-2 right-0 opacity-0 group-hover:opacity-100 transition-opacity pointer-events-none">
              <div className="bg-black text-white text-xs px-3 py-2 rounded-lg whitespace-nowrap">
                Grabaci√≥n con an√°lisis conductual
              </div>
            </div>
          </button>
        </div>
      )}

      {/* Indicador de grabaci√≥n activa (esquina) */}
      {isRecording && (
        <div className="fixed top-4 left-4 z-[200]">
          <div className="flex items-center gap-3 bg-red-600 px-4 py-2 rounded-full shadow-lg">
            <span className="w-3 h-3 bg-white rounded-full animate-pulse"></span>
            <span className="text-white font-mono font-bold">
              {formatDuration(processingState.duration)}
            </span>
            <button
              onClick={stopRecording}
              className="ml-2 bg-white/20 hover:bg-white/30 px-2 py-1 rounded text-xs font-medium transition-colors"
            >
              Detener
            </button>
          </div>
        </div>
      )}
    </>
  );
};

export default RecordingManagerV2;
